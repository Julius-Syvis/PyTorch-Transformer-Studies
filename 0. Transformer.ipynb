{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper 0\n",
    "#### [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "**Goals:**\n",
    " 1. Analyze the `torch.nn.Transformer` implementation\n",
    " 2. Dissect the paper and its implications\n",
    " 3. Set base transformer knowledge for other papers\n",
    " 4. Provide a reference for some obscure PyTorch functions\n",
    " 5. Try some hyperparameter and model combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchtext, spacy\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from torch import optim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. TensorBoard Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'.tf_runs/{datetime.now().strftime(\"%Y-%m-%d %H-%M\")}')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir tf_runs --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. `nn.Transformer` implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing (standard procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine dependent\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = \"en\"\n",
    "trg_lang = \"de\"\n",
    "\n",
    "field_src = Field(tokenize = \"spacy\",\n",
    "                 init_token = '<sos>',\n",
    "                 eos_token = '<eos>',\n",
    "                 tokenizer_language=src_lang,\n",
    "                 lower = True)\n",
    "\n",
    "field_trg = Field(tokenize = \"spacy\", \n",
    "                 init_token = '<sos>',\n",
    "                 eos_token = '<eos>',\n",
    "                 tokenizer_language=trg_lang,\n",
    "                 lower = True)\n",
    "\n",
    "train_data, valid_data, test_data = torchtext.datasets.Multi30k.splits((f'.{src_lang}', f'.{trg_lang}'), [field_src, field_trg])\n",
    "\n",
    "field_src.build_vocab(train_data, min_freq=2)\n",
    "field_trg.build_vocab(train_data, min_freq=2)\n",
    "\n",
    "src_vocab = len(field_src.vocab)\n",
    "trg_vocab = len(field_trg.vocab)\n",
    "\n",
    "src_pad_idx = field_src.vocab.stoi['<pad>']\n",
    "trg_pad_idx = field_trg.vocab.stoi['<pad>']\n",
    "\n",
    "sp_src = spacy.load(src_lang)\n",
    "sp_trg = spacy.load(trg_lang)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = bs, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VERIFY TOKENIZED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two young , white males are outside near many bushes . <-> zwei junge weiße männer sind im freien in der nähe vieler büsche .',\n",
       " 'several men in hard hats are operating a giant pulley system . <-> mehrere männer mit schutzhelmen bedienen ein antriebsradsystem .',\n",
       " 'a little girl climbing into a wooden playhouse . <-> ein kleines mädchen klettert in ein spielhaus aus holz .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(train_data[i].src) + \" <-> \" + \" \".join(train_data[i].trg) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two young , white males are outside near many bushes . <-> zwei junge weiße männer sind im freien in der nähe vieler büsche .',\n",
       " 'several men in hard hats are operating a giant pulley system . <-> mehrere männer mit schutzhelmen bedienen ein antriebsradsystem .',\n",
       " 'a little girl climbing into a wooden playhouse . <-> ein kleines mädchen klettert in ein spielhaus aus holz .']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(train_iterator.dataset[i].src) + \" <-> \" + \" \".join(train_iterator.dataset[i].trg) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The widely used Positional Encoding implementation\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddedTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 d_model, \n",
    "                 src_vocab, \n",
    "                 trg_vocab, \n",
    "                 nhead, \n",
    "                 num_encoder_layers, \n",
    "                 num_decoder_layers, \n",
    "                 dim_feedforward, \n",
    "                 dropout, \n",
    "                 device,\n",
    "                 pad_idx,\n",
    "                 max_len = 100):\n",
    "        super(EmbeddedTransformer, self).__init__()\n",
    "        \n",
    "        # Params\n",
    "        self.d_model = d_model\n",
    "        self.device = device\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        # Model\n",
    "        self.embed_src = nn.Embedding(src_vocab, d_model)\n",
    "        self.embed_trg = nn.Embedding(trg_vocab, d_model)\n",
    "        self.embed_src_pos = PositionalEncoding(d_model, dropout, max_len)\n",
    "        self.embed_trg_pos = PositionalEncoding(d_model, dropout, max_len)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, \n",
    "                                          num_encoder_layers, num_decoder_layers, \n",
    "                                          dim_feedforward, dropout)\n",
    "        self.fc = nn.Linear(d_model, trg_vocab)\n",
    "        \n",
    "        # Initialize parameters\n",
    "        # Warning: no initialization is mentioned in the original paper\n",
    "        # To follow Attention Is All You Need, comment out the following line:\n",
    "        self.init_params()\n",
    "        \n",
    "    def init_params(self):\n",
    "        # As noted in several other sources (not the original paper),\n",
    "        # Xavier initialization drastically improves model performance\n",
    "        \n",
    "        for params in self.parameters():\n",
    "            if params.dim() > 1:\n",
    "                nn.init.xavier_uniform_(params)\n",
    "        \n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        # Unembedded data\n",
    "        # src: [S, N]\n",
    "        # trg: [T, N]\n",
    "        src_len, batch_size = src.shape\n",
    "        trg_len, batch_size = trg.shape\n",
    "        \n",
    "        # First, prepare masks\n",
    "        src_key_padding_mask = (src.transpose(0, 1) == self.pad_idx).to(self.device)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg.shape[0]).to(self.device)\n",
    "        \n",
    "        # src_key_padding_mask: [N, S]\n",
    "        # trg_mask: [T, T]\n",
    "        \n",
    "        # Embed and encode\n",
    "        # src_pos: [S, N]\n",
    "        # trg_pos: [T, N]\n",
    "        \n",
    "        src = self.embed_src(src) * math.sqrt(self.d_model)\n",
    "        src = self.embed_src_pos(src)\n",
    "        src = self.dropout(src)\n",
    "        \n",
    "        trg = self.embed_trg(trg) * math.sqrt(self.d_model)\n",
    "        trg = self.embed_trg_pos(trg)\n",
    "        trg = self.dropout(trg)\n",
    "        \n",
    "        # Embedded data\n",
    "        # src: [S, N, E]\n",
    "        # trg: [T, N, E]\n",
    "        \n",
    "        out = self.transformer(src, trg, src_key_padding_mask=src_key_padding_mask, tgt_mask=trg_mask)\n",
    "        \n",
    "        # out: [T, N, E]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # V = len(TRG_VOCAB)\n",
    "        # out: [T, N, V]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regarding transformer masks:**\n",
    " * All masks are only applied to `nn.MultiheadAttention` module\n",
    " * All `key_padding_mask` types are ignored before calculating attention - well suited to ignore padding tokens and save on calculation\n",
    " * All `key_padding_mask` types use Batch-First arrangement, even though transformer input is SequenceLength-First\n",
    " * Other masks are used as `attn_mask` to mask attention from other elements - prevent them from accessing certain input\n",
    " * `src` masks are used in `nn.TransformerEncoder`\n",
    " * `trg` masks are used in the first `nn.TransformerDecoder` attention layer\n",
    " * `memory` masks are used in the second `nn.TransformerDecoder` attention layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \n",
    "    def __init__(self, model, iterators, criterion, optimizer):\n",
    "        \n",
    "        train_iterator, valid_iterator, test_iterator = iterators\n",
    "        \n",
    "        self.train_iterator = train_iterator\n",
    "        self.valid_iterator = valid_iterator\n",
    "        self.test_iterator = test_iterator\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    \n",
    "    def train(self, eps, verbose = False, translate_every = 1, translation_phrase = \"Three brothers are playing football\"):\n",
    "        \n",
    "        total_time = 0\n",
    "        sequence_time = 0 # reset during print\n",
    "\n",
    "        for e in range(eps):\n",
    "\n",
    "            t1 = time.time()\n",
    "            train_loss = self.train_epoch()\n",
    "            valid_loss = self.evaluate(self.valid_iterator)\n",
    "            t2 = time.time()\n",
    "            sequence_time += (t2 - t1)\n",
    "\n",
    "            if (e+1) % translate_every == 0 or (e+1) == eps:\n",
    "                minutes = int((sequence_time) / 60)\n",
    "                seconds = int((sequence_time) % 60)\n",
    "                if verbose:\n",
    "                    if translate_every > 1:\n",
    "                        translate_num = f\"Epochs {e-translate_every+1}-{e}\"\n",
    "                    else:\n",
    "                        translate_num = f\"Epoch {e}\"\n",
    "                    print(f'\\n{translate_num}: | Time: {minutes}m {seconds}s')\n",
    "                    print(f'Train loss: {train_loss}')\n",
    "                    print(f'Valid loss: {valid_loss}')\n",
    "                    print(translate(translation_phrase))\n",
    "\n",
    "                total_time += sequence_time\n",
    "                sequence_time = 0\n",
    "\n",
    "        test_loss = self.evaluate(self.test_iterator)\n",
    "        minutes = int((total_time) / 60)\n",
    "        seconds = int((total_time) % 60)\n",
    "        if verbose:\n",
    "            print(f'\\nTotal Time: {minutes}m {seconds}s')\n",
    "            print(f'Final test loss: {test_loss}')\n",
    "            \n",
    "            \n",
    "    def train_log(self, eps, writer, diagram_label, instance_label):\n",
    "        for e in range(eps):\n",
    "\n",
    "            train_loss = self.train_epoch()\n",
    "            valid_loss = self.evaluate(self.valid_iterator)\n",
    "            # Write to TensorBoard\n",
    "            writer.add_scalars(diagram_label, {f\"{instance_label} train loss\": train_loss, \n",
    "                                               f\"{instance_label} valid loss\": valid_loss}, e)\n",
    "\n",
    "        writer.close()\n",
    "\n",
    "            \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(self.train_iterator):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            src, trg, out = self.forward(batch)\n",
    "            loss = self.criterion(out, trg)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        mean_loss = total_loss / len(self.train_iterator)\n",
    "        return mean_loss\n",
    "\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(iterator):\n",
    "\n",
    "                src, trg, out = self.forward(batch)\n",
    "                loss = self.criterion(out, trg)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        mean_loss = total_loss / len(iterator)\n",
    "        return mean_loss\n",
    "\n",
    "    \n",
    "    def forward(self, batch, verbose = False):\n",
    "        src = batch.src.to(device) # [S, N]\n",
    "        trg = batch.trg.to(device) # [T + 1, N]\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Data received from iterator: src=[{src.shape}]; trg=[{trg.shape}]')\n",
    "\n",
    "        # Key moment: the -1 index omits the <eos> token\n",
    "        # This is done because the decoder should never receive <eos> as input\n",
    "        out = self.model(src, trg[:-1, :]) # [T, N, V]\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Data received from model: out=[{out.shape}]')\n",
    "\n",
    "        # Key moment: we cut off <sos> token from trg, because the model never learns to output it\n",
    "        # This aligns the out and trg tokens for successful loss calculation\n",
    "        out = out.reshape(-1, out.shape[2]) # [T * N, V]\n",
    "        trg = trg[1:].reshape(-1) # [T * N]\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Data reshaped for loss computation: out=[{out.shape}]; trg=[{trg.shape}]')\n",
    "\n",
    "        return (src, trg, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, verbose = False):\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [token.text.lower() for token in sp_src(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    tokens = [field_src.init_token] + tokens + [field_src.eos_token]\n",
    "    translation = translate_tokens(tokens, verbose)\n",
    "    return translation\n",
    "\n",
    "def translate_tokens(tokens, verbose = False):\n",
    "    model.eval()\n",
    "    idx = [field_src.vocab.stoi[token] for token in tokens]\n",
    "    tensor = torch.LongTensor(idx).unsqueeze(1).to(device)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Tokenized data ready for manual translation: tensor=[{tensor.shape}]')\n",
    "\n",
    "    sos = field_trg.vocab.stoi[\"<sos>\"]\n",
    "    eos = field_trg.vocab.stoi[\"<eos>\"]\n",
    "    target = [sos]\n",
    "    for i in range(20):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(target).unsqueeze(1).to(device)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            out = model(tensor, trg_tensor)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Time step {i}: tensor=[{tensor.shape}]; trg_tensor=[{trg_tensor.shape}]; out=[{out.shape}]')\n",
    "\n",
    "        choice = out.argmax(2)[-1, :].item()\n",
    "        target.append(choice)\n",
    "\n",
    "        if choice == eos:\n",
    "            break\n",
    "\n",
    "    translation = [field_trg.vocab.itos[i] for i in target]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'The final result has {len(translation)-1} tokens (<sos> excluded)')\n",
    "    \n",
    "    return translation[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(data, src_field, trg_field, model, device, verbose = False, max_len = 100):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for datum in data:\n",
    "        \n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        \n",
    "        pred_trg = translate(src)[:-1]\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    score = bleu_score(pred_trgs, trgs) \n",
    "    \n",
    "    t2 = time.time()\n",
    "    minutes = int((t2 - t1) / 60)\n",
    "    seconds = int((t2 - t1) % 60)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'\\nTotal Time: {minutes}m {seconds}s')\n",
    "        \n",
    "    return score * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model, Optimizer & Criterion\n",
    "\n",
    "As in the paper, I've applied 0.9 and 0.98 to Adam betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    trg_pad_idx,\n",
    "    device,\n",
    "    d_model = 512,\n",
    "    nhead = 8,\n",
    "    num_encoder_layers = 6,\n",
    "    num_decoder_layers = 6,\n",
    "    dim_feedforward = 2048,\n",
    "    dropout = 0.1,\n",
    "    max_len = 100,\n",
    "    warmup_steps = 4000):\n",
    "    \n",
    "    # Model\n",
    "    model = EmbeddedTransformer(d_model, src_vocab, trg_vocab, nhead, \n",
    "                                num_encoder_layers, num_decoder_layers, \n",
    "                                dim_feedforward, dropout, \n",
    "                                device, src_pad_idx, max_len)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98))\n",
    "    optimizer = OptimWrapper(optimizer, d_model, warmup_steps)\n",
    "        \n",
    "    # Criterion\n",
    "    # Possible addition - a label smoothing module\n",
    "    # Didn't manage to make one myself\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "    \n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the paper:\n",
    "# lr = d_model ^ -0.5 * min (step_num ^ -0.5, step_num * warmup_steps ^ (-1.5))\n",
    "# warmup_steps = 4000\n",
    "\n",
    "class OptimWrapper():\n",
    "    \n",
    "    def __init__(self, optimizer, d_model, warmup_steps = 4000):\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.step_num = 0\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        self.step_num += 1\n",
    "        new_lr = self.get_lr(self.step_num)\n",
    "            \n",
    "        # Update wrapped optimizer learning rate\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = new_lr\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def get_lr(self, step):\n",
    "        return (self.d_model ** (-0.5)) * min(step ** (-0.5), \n",
    "                                              step * (self.warmup_steps ** (-1.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: most `warmup_steps` values work the same in terms of convergence speed and there are some Adam values that work better than the implemented OptimWrapper class. What's going on? Two proposals:\n",
    " 1. `warmup_steps` are only necessary when training larger models for more steps\n",
    " 2. It's used to make the model more stable during early epochs\n",
    " \n",
    "Worth experimenting with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs 0-4: | Time: 6m 57s\n",
      "Train loss: 2.165329550068809\n",
      "Valid loss: 1.9931537955999374\n",
      "['drei', '<unk>', 'spielen', 'fußball', 'fußball', '.', '<eos>']\n",
      "\n",
      "Epochs 5-9: | Time: 7m 1s\n",
      "Train loss: 1.5920069826857108\n",
      "Valid loss: 1.6191014498472214\n",
      "['drei', '<unk>', 'spielen', 'football', '.', '<eos>']\n",
      "\n",
      "Epochs 10-14: | Time: 6m 57s\n",
      "Train loss: 1.2036513230611574\n",
      "Valid loss: 1.507385604083538\n",
      "['drei', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche', 'weibliche']\n",
      "\n",
      "Epochs 15-19: | Time: 6m 51s\n",
      "Train loss: 0.9207143026038939\n",
      "Valid loss: 1.4476560205221176\n",
      "['drei', '<unk>', 'spielen', 'football', '.', '<eos>']\n",
      "\n",
      "Total Time: 27m 48s\n",
      "Final test loss: 1.533690869808197\n"
     ]
    }
   ],
   "source": [
    "small_model = ([256, 8, 3, 3, 512], 10, 1000) # Overfits after 10eps\n",
    "default_model = ([512, 8, 6, 6, 2048], 20, 4000) # Overfits after 20eps\n",
    "selected, eps, warmup_steps = default_model\n",
    "\n",
    "model, optimizer, criterion = build_model(trg_pad_idx, device, *selected, warmup_steps = warmup_steps)\n",
    "trainer = Trainer(model, (train_iterator, valid_iterator, test_iterator), criterion, optimizer)\n",
    "\n",
    "trainer.train(eps, True, translate_every = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually evaluate model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eine', 'mutter', 'ist', '<unk>', 'mutter', 'in', 'einem', 'krankenhaus', 'und', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'mutter', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"My mother is in the hospital\"\n",
    "translation = translate(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drei', '<unk>', 'spielen', 'football', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Three brothers are playing football\"\n",
    "translation = translate(sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate BLEU (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Time: 7m 18s\n",
      "BLEU score = 28.59\n"
     ]
    }
   ],
   "source": [
    "bleu_sc = calculate_bleu(test_data, field_src, field_trg, model, device, True)\n",
    "print(f'BLEU score = {bleu_sc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9080"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.step_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path(\".states\")\n",
    "states = PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.funcs import *\n",
    "\n",
    "path_m0 = PATH/'m0.pth'\n",
    "\n",
    "save_whole(model, optimizer, path_m0)\n",
    "model_, optimizer_ = load_whole(path_m0)\n",
    "\n",
    "# save(model, optimizer, path_m0)\n",
    "\n",
    "# model_state, optimizer_state = load(path_m0)\n",
    "# model_, optimizer_ = build_model(trg_pad_idx, device)\n",
    "# model_.load_state_dict(model_state)\n",
    "# optimizer_.load_state_dict(optimizer_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with optimizer params\n",
    "\n",
    "Trying to find good warmup_steps values for this smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 20 # Results in ~4.5k steps\n",
    "ws = [\n",
    "    0,\n",
    "    500,\n",
    "    1000,\n",
    "    2000,\n",
    "    4000, # Used in the paper\n",
    "]\n",
    "\n",
    "for w in ws:\n",
    "    model, optimizer, criterion = build_model(trg_pad_idx, device) # Default model\n",
    "    trainer = Trainer(model, (train_iterator, valid_iterator, test_iterator), criterion, optimizer)\n",
    "    trainer.train_log(eps, writer, f\"Default Model {eps}ep Warmup Steps\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions to ask: \n",
    "#  Do some of these converge faster?\n",
    "#  Do some of these overfit more?\n",
    "#  Do some of these underfit more?\n",
    "#  Is there a good ratio?\n",
    "#  Does encoder-decoder depth ratio matter?\n",
    "#  Which ones could perform well when trained more?\n",
    "\n",
    "# Models selected for faster training on a small machine\n",
    "models = [\n",
    "    # Variations of first small-scale model:\n",
    "    [256, 8, 3, 3, 512],\n",
    "    [256, 8, 6, 6, 512],\n",
    "    [256, 8, 3, 3, 1024], # Lowest loss after 10 epochs\n",
    "    [512, 8, 3, 3, 512],\n",
    "    [256, 16, 3, 3, 512],\n",
    "    [256, 4, 3, 3, 512],  # Last 3 models were equally good - nhead seems to matter little\n",
    "    \n",
    "    # Variations of PyTorch-default model:\n",
    "    [512, 8, 6, 6, 2048], # Good model (can train for longer than small models)\n",
    "    [512, 8, 6, 6, 1024], # Good model (can train for longer than small models)\n",
    "    [512, 8, 3, 3, 2048], # Good model (converged faster than previous 2, but overfit faster)\n",
    "    [512, 8, 3, 6, 2048],\n",
    "    [512, 8, 6, 3, 2048],\n",
    "    [512, 8, 3, 9, 2048], # Diverged and then never converged again\n",
    "    [512, 8, 9, 3, 2048], # The worst model except for 3-9\n",
    "    [1024, 8, 3, 3, 2048],\n",
    "    [512, 16, 6, 6, 1024], # The only model still improving during 25th epoch\n",
    "    \n",
    "    # A larger model\n",
    "    [512, 8, 6, 6, 4096] # This variation supposedly does well in the paper\n",
    "                         # Did Ok (average, but slower overfit) in my tests\n",
    "]\n",
    "eps = 25\n",
    "\n",
    "for m in models:\n",
    "    model, optimizer, criterion = build_model(trg_pad_idx, device, *m)\n",
    "    trainer = Trainer(model, (train_iterator, valid_iterator, test_iterator), criterion, optimizer)\n",
    "    trainer.train_log(eps, writer, \"Model Evaluation\", \"-\".join(map(str, m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture parting thoughts:\n",
    "* 3-9, 9-3, 3-6, 6-3 encoder-decoder ratios didn't pay off\n",
    "* Most models memorized the data well (training loss kept decreasing after 20 epochs)\n",
    "* All models stopped improving by the 10th epoch and started overfitting by the 20th\n",
    "* \"Smaller\" models reached the same accuracy in a shorter amount of time - might still need bigger models for bigger datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
